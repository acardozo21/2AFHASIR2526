<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cuantización de Modelos LLM - Proyecto Phi-3</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {
            --bg-color: #0d1117;
            --text-color: #c9d1d9;
            --accent-color: #58a6ff;
            --card-bg: #161b22;
            --code-bg: #21262d;
            --border-color: #30363d;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            margin: 0;
            padding: 0;
        }
        nav {
            background-color: var(--card-bg);
            border-bottom: 1px solid var(--border-color);
            position: sticky;
            top: 0;
            z-index: 100;
            padding: 1rem 2rem;
        }
        nav ul {
            list-style: none;
            padding: 0;
            margin: 0;
            display: flex;
            gap: 20px;
            justify-content: center;
        }
        nav a {
            color: var(--accent-color);
            text-decoration: none;
            font-weight: bold;
            font-size: 1.1rem;
        }
        nav a:hover { text-decoration: underline; }
        .container {
            max-width: 900px;
            margin: 2rem auto;
            padding: 0 1rem;
        }
        h1, h2, h3 {
            color: #ffffff;
            border-bottom: 1px solid var(--border-color);
            padding-bottom: 0.5rem;
        }
        .card {
            background-color: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 2rem;
            margin-bottom: 2rem;
        }
        pre {
            background-color: var(--code-bg);
            padding: 1rem;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }
        code {
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
            color: #79c0ff;
            font-size: 0.9em;
        }
        
     
        .img-container {
            width: 100%;
            margin: 1.5rem 0;
            text-align: center;
        }
        img { 
            max-width: 100%; 
            height: auto; 
            border-radius: 8px; 
            box-shadow: 0 4px 6px rgba(0,0,0,0.3); 
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }
        th, td {
            border: 1px solid var(--border-color);
            padding: 0.8rem;
            text-align: left;
        }
        th { background-color: var(--code-bg); color: white; }
        
        .chart-container {
            position: relative;
            height: 400px;
            width: 100%;
            margin-top: 20px;
        }
        .highlight { color: var(--accent-color); font-weight: bold; }
        .caption {
            display: block;
            text-align: center;
            font-size: 0.9em;
            color: #8b949e;
            margin-top: 0.5rem;
        }
    </style>
</head>
<body>
    <nav>
        <ul>
            <li><a href="#intro">¿Qué es?</a></li>
            <li><a href="#pasos">Paso a Paso</a></li>
            <li><a href="#diferencias">Diferencias</a></li>
        </ul>
    </nav>
    <div class="container">
        <header style="text-align: center; margin-bottom: 3rem;">
            <h1>Proyecto de Cuantización: Phi-3</h1>
            <p>Optimización de LLMs para ejecución local eficiente</p>
        </header>

        <section id="intro" class="card">
            <h2>¿Qué es la Cuantización?</h2>
            <p>La cuantificación reduce el número de bits para representar los pesos del modelo. Permite ejecutar LLMs en hardware limitado reduciendo la memoria RAM necesaria sin perder mucha precisión.</p>
        </section>

        <section id="pasos" class="card">
                <h2>Checklist de Generación (macOS)</h2>
                <p>Este es el flujo completo que seguí para cuantizar <code>Phi-3-mini-4k-instruct</code> y usarlo en LM Studio.</p>
            
                <h3>1. Preparar el entorno</h3>
                <pre><code>mkdir ~/cuantizacion-phi3 && cd ~/cuantizacion-phi3
            brew install git-lfs && git lfs install
            git clone https://github.com/ggerganov/llama.cpp.git
            python3 -m venv venv && source venv/bin/activate
            pip install -r llama.cpp/requirements.txt torch transformers huggingface-hub</code></pre>
                <p>Con esto dejas listo <strong>llama.cpp</strong>, el entorno virtual de Python y todas las dependencias necesarias para convertir el modelo.</p>
            
                <h3>2. Descargar el modelo original</h3>
                <pre><code>git clone https://huggingface.co/microsoft/Phi-3-mini-4k-instruct</code></pre>
                <p>Este repositorio contiene el modelo en formato de Hugging Face (<code>pytorch_model.bin</code> y archivos de configuración).</p>
            
                <h3>3. Cuantizar a GGUF (Q4_K_M)</h3>
                <pre><code>python3 llama.cpp/convert_hf_to_gguf.py ./Phi-3-mini-4k-instruct \
             --outtype q4_k_m \
             --outfile phi-3-mini-q4_k_m.gguf</code></pre>
                <p>Aquí se convierte el modelo de precisión completa a un modelo <strong>cuantizado</strong> en formato <code>.gguf</code>, reduciendo tamaño y mejorando la velocidad.</p>
            
                <h3>4. Instalar el modelo en LM Studio</h3>
                <pre><code>mkdir -p ~/Library/Application\ Support/LMStudio/models/Microsoft/Phi-3-mini-4k-instruct
            cp phi-3-mini-q4_k_m.gguf ~/Library/Application\ Support/LMStudio/models/Microsoft/Phi-3-mini-4k-instruct/</code></pre>
                <p>Copias el archivo cuantizado a la carpeta de modelos de LM Studio para que aparezca en la lista de modelos locales.</p>
            
                <h3>5. Probar el modelo cuantizado en LM Studio</h3>
                <pre><code># En LM Studio:
            # 1. AI Chat → Microsoft/Phi-3-mini-4k-instruct → Load
            # 2. Prompt de prueba:
            Explica qué es la cuantización</code></pre>
                <p>En esta prueba comprobaste que el modelo pasa de ~7,1&nbsp;GB a ~2,3&nbsp;GB y genera más rápido manteniendo buena calidad de respuesta.</p>
        </section>

        <section id="diferencias" class="card">
            <h2>Comparativa</h2>
            
     
            <div class="img-container">
                <img src="1.png" alt="1">
                <span class="caption">Fig 1. Comparación de consumo de memoria en LM Studio</span>
            </div>

            <table>
                <thead>
                    <tr><th>Métrica</th><th>Original (F16)</th><th>Cuantizado (Q4)</th></tr>
                </thead>
                <tbody>
                    <tr><td>Tamaño</td><td>7.12 GB</td><td class="highlight">2.23 GB</td></tr>
                    <tr><td>Velocidad</td><td>12.74 t/s</td><td class="highlight">30.36 t/s</td></tr>
                </tbody>
            </table>

            <h3>Gráfico de Rendimiento</h3>
            <div class="chart-container">
                <canvas id="myChart"></canvas>
            </div>

          
            <div class="img-container" style="margin-top: 3rem;">
                <img src="2.png" alt="2">
                <span class="caption">Fig 2. Calidad de respuesta y métricas de generación</span>
            </div>
        </section>
    </div>

    <script>
        const ctx = document.getElementById('myChart').getContext('2d');
        const myChart = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: ['Tamaño (GB) - ', 'Velocidad (t/s) - '],
                datasets: [{
                    label: 'Modelo sin cuantizar',
                    data: [7.12, 12.74],
                    backgroundColor: 'rgba(255, 99, 132, 0.6)',
                    borderColor: 'rgba(255, 99, 132, 1)',
                    borderWidth: 1
                },
                {
                    label: 'Modelo Cuantizado',
                    data: [2.23, 30.36],
                    backgroundColor: 'rgba(75, 192, 192, 0.6)',
                    borderColor: 'rgba(75, 192, 192, 1)',
                    borderWidth: 1
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: { 
                        beginAtZero: true, 
                        grid: { color: '#30363d' },
                        ticks: { color: '#c9d1d9' }
                    },
                    x: { 
                        grid: { color: '#30363d' },
                        ticks: { color: '#c9d1d9' }
                    }
                },
                plugins: {
                    legend: { labels: { color: '#c9d1d9' } }
                }
            }
        });
    </script>
</body>
</html>

