<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Curso IA – Destilación de Conocimiento</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        :root {
            --primario: #4f46e5;
            --primario-oscuro: #3730a3;
            --fondo: #0f172a;
            --fondo-claro: #111827;
            --texto: #e5e7eb;
            --acento: #22c55e;
        }

        * {
            box-sizing: border-box;
            scroll-behavior: smooth;
        }

        body {
            margin: 0;
            font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
            background: radial-gradient(circle at top, #1f2937 0, #020617 55%);
            color: var(--texto);
        }

        /* Barra de navegación */
        header {
            position: sticky;
            top: 0;
            z-index: 50;
            background: rgba(15, 23, 42, 0.95);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid rgba(148, 163, 184, 0.3);
        }

        .nav-container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 0.75rem 1.5rem;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }

        .nav-logo {
            font-weight: 700;
            letter-spacing: 0.08em;
            text-transform: uppercase;
            font-size: 0.95rem;
            color: #e5e7eb;
        }

        .nav-logo span { color: var(--acento); }

        nav a {
            margin-left: 1.4rem;
            text-decoration: none;
            color: #9ca3af;
            font-size: 0.9rem;
            position: relative;
        }

        nav a::after {
            content: "";
            position: absolute;
            left: 0;
            bottom: -0.3rem;
            width: 0;
            height: 2px;
            background: linear-gradient(90deg, var(--primario), var(--acento));
            transition: width 0.2s ease;
        }

        nav a:hover { color: #e5e7eb; }
        nav a:hover::after { width: 100%; }

        /* Layout general */
        main {
            max-width: 1100px;
            margin: 0 auto;
            padding: 2rem 1.5rem 3rem;
        }

        section {
            padding: 2.5rem 1.8rem;
            margin-bottom: 1.8rem;
            background: radial-gradient(circle at top left, #1f2937 0, #020617 55%);
            border-radius: 1.2rem;
            border: 1px solid rgba(148, 163, 184, 0.35);
            box-shadow: 0 22px 45px rgba(15, 23, 42, 0.7);
        }

        section h2 {
            margin-top: 0;
            font-size: 1.5rem;
            margin-bottom: 0.75rem;
        }

        section h3 {
            margin-top: 1.4rem;
            margin-bottom: 0.35rem;
            font-size: 1.1rem;
            color: #e5e7eb;
        }

        p {
            line-height: 1.7;
            font-size: 0.97rem;
            color: #d1d5db;
            margin: 0.4rem 0 0.6rem;
        }

        ul, ol {
            margin: 0.5rem 0 0.5rem 1.1rem;
            padding-left: 0.5rem;
            color: #d1d5db;
            font-size: 0.95rem;
        }

        code {
            font-family: "Fira Code", Menlo, Monaco, Consolas, "Liberation Mono", monospace;
            background: rgba(15, 23, 42, 0.9);
            border-radius: 0.45rem;
            padding: 0.85rem 1rem;
            display: block;
            overflow-x: auto;
            font-size: 0.86rem;
            border: 1px solid rgba(148, 163, 184, 0.4);
            margin: 0.7rem 0;
        }

        .hero {
            display: grid;
            grid-template-columns: minmax(0, 3fr) minmax(0, 2.1fr);
            gap: 2rem;
            align-items: center;
        }

        .hero-badge {
            display: inline-flex;
            align-items: center;
            padding: 0.3rem 0.6rem;
            border-radius: 999px;
            border: 1px solid rgba(148, 163, 184, 0.5);
            font-size: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.15em;
            margin-bottom: 0.75rem;
            color: #9ca3af;
        }

        .hero-title { font-size: 2rem; margin: 0 0 0.4rem; }
        .hero-sub { font-size: 0.98rem; color: #cbd5f5; }

        .hero-highlight {
            margin-top: 0.9rem;
            border-left: 3px solid var(--primario);
            padding-left: 0.8rem;
            font-size: 0.9rem;
            color: #e5e7eb;
        }

        .hero-taglist {
            margin-top: 1rem;
            display: flex;
            flex-wrap: wrap;
            gap: 0.45rem;
        }

        .tag {
            font-size: 0.78rem;
            padding: 0.25rem 0.6rem;
            border-radius: 999px;
            background: rgba(55, 65, 81, 0.6);
            border: 1px solid rgba(148, 163, 184, 0.5);
            color: #e5e7eb;
        }

        .hero-image-wrapper {
            border-radius: 1rem;
            overflow: hidden;
            border: 1px solid rgba(148, 163, 184, 0.4);
            background: #020617;
            max-width: 650px;      /* más grande */
            margin: 0 auto;
        }

        .hero-image-wrapper img {
            display: block;
            width: 100%;
            height: auto;
        }

        .img-caption {
            font-size: 0.8rem;
            text-align: center;
            color: #9ca3af;
            padding: 0.45rem 0.7rem 0.6rem;
            background: linear-gradient(to right, #020617, #111827);
        }

        .callout {
            margin-top: 0.8rem;
            padding: 0.8rem 1rem;
            border-radius: 0.8rem;
            border: 1px solid rgba(45, 212, 191, 0.45);
            background: linear-gradient(135deg, rgba(8, 47, 73, 0.9), rgba(15, 23, 42, 0.95));
            font-size: 0.9rem;
        }

        .steps-grid {
            display: grid;
            grid-template-columns: minmax(0, 1.4fr) minmax(0, 1.1fr);
            gap: 1.8rem;
            align-items: flex-start;
        }

        .steps-list h3 span {
            font-size: 0.8rem;
            padding: 0.1rem 0.5rem;
            border-radius: 999px;
            background: rgba(37, 99, 235, 0.18);
            border: 1px solid rgba(96, 165, 250, 0.6);
            margin-right: 0.4rem;
        }

        .metric-grid {
            display: grid;
            grid-template-columns: repeat(3, minmax(0, 1fr));
            gap: 1rem;
            margin-top: 1rem;
        }

        .metric-card {
            padding: 0.75rem 0.9rem;
            border-radius: 0.9rem;
            background: rgba(15, 23, 42, 0.9);
            border: 1px solid rgba(148, 163, 184, 0.45);
            font-size: 0.85rem;
        }

        .metric-card strong { display: block; margin-bottom: 0.2rem; }

        .footer-note {
            font-size: 0.8rem;
            text-align: center;
            color: #9ca3af;
            margin-top: 1.2rem;
        }

        @media (max-width: 880px) {
            .hero,
            .steps-grid {
                grid-template-columns: minmax(0, 1fr);
            }
            nav { display: none; }
            section { padding: 1.7rem 1.2rem; }
            main { padding-inline: 1rem; }
        }
    </style>
</head>
<body>

<header>
    <div class="nav-container">
        <div class="nav-logo">CURSO <span>IA</span> · DESTILACIÓN</div>
        <nav>
            <a href="#intro">Inicio</a>
            <a href="#concepto">¿Qué es?</a>
            <a href="#proceso">Pasos</a>
            <a href="#tipos">Tipos</a>
            <a href="#practica">Práctica</a>
        </nav>
    </div>
</header>

<main>

    <!-- INTRO / HERO -->
    <section id="intro">
        <div class="hero">
            <div>
                <div class="hero-badge">Curso práctico · LLMs</div>
                <h1 class="hero-title">Destilación de Conocimiento en Modelos de Lenguaje</h1>
                <p class="hero-sub">
                    Aprende paso a paso cómo un modelo gigante actúa como <strong>profesor</strong> para entrenar a un modelo diminuto que mantiene casi la misma inteligencia, pero es muchísimo más rápido.
                </p>
                <div class="hero-highlight">
                    Imagina a un chef de renombre mundial enseñando a un aprendiz: no solo entrega la receta, también comparte sus trucos, proporciones y forma de pensar al combinar ingredientes.
                </div>
                <div class="hero-taglist">
                    <span class="tag">Knowledge Distillation</span>
                    <span class="tag">Hugging Face</span>
                    <span class="tag">Transformers</span>
                    <span class="tag">PyTorch</span>
                </div>
            </div>

            <div class="hero-image-wrapper">
                <!-- al hacer clic se abre grande en una pestaña nueva -->
                <a href="d1.png" target="_blank">
                    <img src="d1.png" alt="Resultados profesor vs estudiante">
                </a>
                <div class="img-caption">
                    Comparativa de precisión y rendimiento entre el modelo profesor y el modelo estudiante tras la destilación.
                </div>
            </div>
        </div>
    </section>

    <!-- CONCEPTO -->
    <section id="concepto">
        <h2>1. ¿Qué es la destilación de conocimiento?</h2>
        <p>
            La destilación es una técnica de entrenamiento en la que un modelo grande (<strong>profesor</strong>) transfiere su conocimiento a un modelo mucho más pequeño (<strong>estudiante</strong>) para que aprenda a imitar su comportamiento.
        </p>
        <p>
            En lugar de entrenar al estudiante solo con etiquetas duras como “positivo” o “negativo”, se usan distribuciones de probabilidad completas, lo que se conoce como conocimiento oscuro o <em>dark knowledge</em>.
        </p>

        <h3>Elementos clave</h3>
        <p>Estos son los actores principales en el proceso de destilación:</p>
        <ul>
            <li><strong>Modelo Profesor</strong>: modelo de última generación, grande y costoso de ejecutar (por ejemplo, DistilBERT finetuneado para sentimientos).</li>
            <li><strong>Modelo Estudiante</strong>: versión diminuta que busca copiar el comportamiento del profesor manteniendo rapidez y eficiencia.</li>
            <li><strong>Conocimiento oscuro</strong>: probabilidades detalladas que explican qué clase es más probable y qué alternativas son menos probables, capturando matices y relaciones entre clases.</li>
        </ul>

        <div class="callout">
            El estudiante no solo aprende “la respuesta correcta”, sino también <strong>cómo razona el profesor</strong> para llegar hasta ella.
        </div>
    </section>

    <!-- BENEFICIOS -->
    <section id="beneficios">
        <h2>2. ¿Para qué sirve la destilación?</h2>
        <p>
            La destilación permite convertir un modelo pesado de laboratorio en un modelo ligero listo para producción sin perder demasiado rendimiento.
        </p>
        <ul>
            <li><strong>Modelos especializados y eficientes</strong>: ideales para tareas concretas, como clasificación de sentimientos o moderación de contenido.</li>
            <li><strong>Reducción de costes</strong>: un modelo pequeño reduce el consumo de memoria, GPU/CPU y el coste por petición en producción.</li>
            <li><strong>Despliegue en móviles y edge</strong>: hace posible ejecutar IA avanzada en teléfonos, portátiles o dispositivos embebidos.</li>
            <li><strong>Retención de capacidades complejas</strong>: a diferencia de técnicas como la poda o la cuantización, el estudiante reaprende el comportamiento desde cero, heredando patrones de alto nivel.</li>
        </ul>

        <div class="metric-grid">
            <div class="metric-card">
                <strong>Profesor</strong>
                <span>≈ 67M parámetros, muy preciso pero pesado.</span>
            </div>
            <div class="metric-card">
                <strong>Estudiante</strong>
                <span>≈ 4.4M parámetros, unas 15 veces más pequeño.</span>
            </div>
            <div class="metric-card">
                <strong>Ventaja</strong>
                <span>Velocidad y coste de inferencia muy reducidos manteniendo gran parte de la capacidad.</span>
            </div>
        </div>
    </section>

    <!-- PROCESO -->
    <section id="proceso">
        <h2>3. ¿Cómo funciona? · Flujo de trabajo</h2>

        <div class="steps-grid">
            <div class="steps-list">
                <h3><span>01</span> Preparar el conjunto de datos</h3>
                <p>
                    Seleccionas un dataset representativo de la tarea (en este curso, usaremos <strong>SST-2</strong>, un clásico para análisis de sentimientos con frases positivas y negativas).
                </p>

                <h3><span>02</span> Generar etiquetas blandas del profesor</h3>
                <p>
                    Pasas todas las frases por el modelo profesor y guardas su distribución de probabilidades para cada clase, no solo la etiqueta final.
                </p>

                <h3><span>03</span> Entrenar al modelo estudiante</h3>
                <p>El estudiante aprende con una función de pérdida que combina:</p>
                <ul>
                    <li><strong>Student Loss</strong>: compara las predicciones del estudiante con las etiquetas verdaderas del dataset.</li>
                    <li><strong>Distillation Loss</strong>: compara la distribución del estudiante con la del profesor mediante divergencia KL.</li>
                </ul>

                <h3><span>04</span> Evaluar, comparar y desplegar</h3>
                <p>
                    Evalúas accuracy, tamaño y velocidad; si el estudiante se acerca al rendimiento del profesor con mucha menos memoria, está listo para producción.
                </p>
            </div>

            <div class="hero-image-wrapper">
                <a href="d2.png" target="_blank">
                    <img src="d2.png" alt="Resumen destilación">
                </a>
                <div class="img-caption">
                    Resumen de la destilación: reducción de parámetros, precisión obtenida y calidad de la imitación medida con divergencia KL.
                </div>
            </div>
        </div>

        <div class="callout">
            La clave está en la función de pérdida: mezclas la pérdida estándar de clasificación con la pérdida de distilación para que el estudiante aprenda tanto de los datos reales como del comportamiento detallado del profesor.
        </div>
    </section>

    <!-- TIPOS -->
    <section id="tipos">
        <h2>4. Tipos de destilación y consideraciones</h2>
        <p>
            La destilación no se limita a copiar salidas finales; también puede transferir estructuras internas y relaciones entre representaciones.
        </p>
        <ul>
            <li><strong>Response-Based</strong>: el estudiante imita directamente las probabilidades de salida del profesor, es la variante más usada y la que aplicamos aquí.</li>
            <li><strong>Feature-Based</strong>: el estudiante aprende a replicar activaciones intermedias, como si copiara la forma en que el profesor “procesa” la información paso a paso.</li>
            <li><strong>Relation-Based</strong>: se centra en las relaciones entre ejemplos o capas, capturando cómo el profesor organiza el espacio de representación.</li>
        </ul>
        <p>
            Siempre existe un equilibrio entre tamaño y rendimiento: un estudiante extremadamente pequeño puede perder capacidad en tareas muy complejas, aunque en dominios concretos el comportamiento puede ser casi indistinguible del profesor.
        </p>
    </section>

    <!-- PRÁCTICA -->
    <section id="practica">
        <h2>5. Práctica guiada: destilación de un clasificador de sentimientos</h2>
        <p>
            En la parte práctica destilarás un modelo basado en DistilBERT (profesor) a un modelo <strong>bert-tiny</strong> (estudiante) usando PyTorch y la librería Transformers de Hugging Face.
        </p>

        <h3>5.1 Preparar el entorno</h3>
        <p>
            Crea una carpeta de proyecto, activa un entorno virtual de Python e instala las dependencias necesarias:
        </p>
        <code>
python -m venv venv
venv\Scripts\activate   # En Windows
# o: source venv/bin/activate  # En Linux/Mac

pip install transformers datasets torch scikit-learn
        </code>

        <h3>5.2 Cargar modelos, tokenizador y dataset</h3>
        <p>
            En un archivo <strong>destilar.py</strong> importa las librerías y carga el modelo profesor, el modelo estudiante y el dataset SST-2.
        </p>
        <code>
import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from sklearn.metrics import accuracy_score, f1_score

teacher_id = "distilbert-base-uncased-finetuned-sst-2-english"
student_id = "prajjwal1/bert-tiny"

teacher_model = AutoModelForSequenceClassification.from_pretrained(teacher_id)
student_model = AutoModelForSequenceClassification.from_pretrained(student_id, num_labels=2)

tokenizer = AutoTokenizer.from_pretrained(student_id)
dataset = load_dataset("sst2")

def tokenize_data(examples):
    return tokenizer(examples["sentence"], truncation=True, padding="max_length")

tokenized_dataset = dataset.map(tokenize_data, batched=True)
tokenized_dataset = tokenized_dataset.rename_column("label", "labels")
        </code>

        <h3>5.3 Definir el entrenador de destilación</h3>
        <p>
            Creamos una clase <strong>DistillationTrainer</strong> que añade la pérdida de destilación mediante divergencia KL a la pérdida estándar del estudiante.
        </p>
        <code>
import torch.nn.functional as F

class DistillationTrainer(Trainer):
    def __init__(self, *args, teacher_model=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.teacher_model = teacher_model
        if self.args.device.type == "cuda":
            self.teacher_model.to(self.args.device)
        self.teacher_model.eval()

    def compute_loss(self, model, inputs, return_outputs=False):
        outputs_student = model(**inputs)
        student_loss = outputs_student.loss

        with torch.no_grad():
            outputs_teacher = self.teacher_model(**inputs)

        loss_distillation = F.kl_div(
            input=F.log_softmax(outputs_student.logits / 2.0, dim=-1),
            target=F.softmax(outputs_teacher.logits / 2.0, dim=-1),
            reduction="batchmean"
        ) * (2.0 ** 2)

        loss = 0.2 * student_loss + 0.8 * loss_distillation
        return (loss, outputs_student) if return_outputs else loss
        </code>

        <h3>5.4 Entrenar el estudiante</h3>
        <p>
            Configura los argumentos de entrenamiento, define las métricas y lanza la destilación.
        </p>
        <code>
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    f1 = f1_score(labels, preds, average="weighted")
    acc = accuracy_score(labels, preds)
    return {"accuracy": acc, "f1": f1}

training_args = TrainingArguments(
    output_dir="distilled_model",
    num_train_epochs=3,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    logging_steps=100,
    push_to_hub=False
)

trainer = DistillationTrainer(
    model=student_model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["validation"],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
    teacher_model=teacher_model
)

print("Iniciando la destilación...")
trainer.train()
        </code>

        <h3>5.5 Evaluación y comparación final</h3>
        <p>
            Finalmente compara el tamaño de los modelos y la ganancia en eficiencia que has conseguido.
        </p>
        <code>
teacher_params = teacher_model.num_parameters() / 1_000_000
student_params = student_model.num_parameters() / 1_000_000

print("\n--- Comparación Final ---")
print(f"Parámetros del Profesor: {teacher_params:.2f}M")
print(f"Parámetros del Estudiante: {student_params:.2f}M")
print(f"Reducción de tamaño: {teacher_params / student_params:.1f}x")
        </code>

        <div class="callout">
            Un resultado típico es pasar de ~67M a ~4.4M de parámetros, obteniendo un modelo unas 15 veces más pequeño, con una precisión todavía muy alta para análisis de sentimientos.
        </div>

        <div class="footer-note">
            Consejo: guarda tu modelo estudiante entrenado y úsalo en tus propias APIs o aplicaciones web para ofrecer análisis de sentimientos rápidos y baratos.
        </div>
    </section>

</main>

</body>
</html>
